#!/data/data/com.termux/files/usr/bin/python3
import telebot
import requests
import os
import random
import re
import time
from dotenv import load_dotenv

load_dotenv()

# ==================== CONFIGURATION AVANCÃ‰E ====================
bot = telebot.TeleBot(os.getenv('TELEGRAM_TOKEN'))
GROQ_API_KEY = os.getenv('GROQ_API_KEY')
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"

# ğŸ‘‘ IDENTITÃ‰ PRESTIGIEUSE
CREATOR = "ğŸ‘‘ Soszoe"
BOT_NAME = "ğŸ”¥ KervensAI Ultra"
VERSION = "âœ¨ Ã‰dition Exclusive"

# ğŸ¨ TES PHOTOS PERSONNELLES - Remplace ces URLs par tes propres images
IMAGE_GALLERY = [
    "https://files.catbox.moe/601u5z.jpg",  # Remplace avec ton image 1
    "https://files.catbox.moe/qmxfpk.jpg",  # Remplace avec ton image 2  
    "https://files.catbox.moe/77iazb.jpg",  # Remplace avec ton image 3
    "https://files.catbox.moe/tta6ta.jpg",  # Remplace avec ton image 4
    "https://files.catbox.moe/tta6ta.jpg",  # Remplace avec ton image 5
]

# âš¡ MODÃˆLES OPTIMISÃ‰S
MODEL_CONFIG = {
    "ğŸš€ Llama-70B": "llama-3.1-70b-versatile",
    "âš¡ Llama-8B": "llama-3.1-8b-instant", 
    "ğŸ¯ Mixtral": "mixtral-8x7b-32768"
}

current_model = MODEL_CONFIG["âš¡ Llama-8B"]  # ModÃ¨le plus rapide par dÃ©faut

# ==================== FONCTIONS AMÃ‰LIORÃ‰ES ====================
def test_groq_connection():
    """Test robuste de la connexion Groq"""
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "messages": [{"role": "user", "content": "Test"}],
        "model": current_model,
        "max_tokens": 10,
        "temperature": 0.1
    }
    
    try:
        response = requests.post(GROQ_API_URL, json=payload, headers=headers, timeout=10)
        return response.status_code == 200
    except:
        return False

def create_stylish_menu():
    """Menu stylisÃ© avec tes photos"""
    return f"""
ğŸŠ **{BOT_NAME}** ğŸŠ
{VERSION}

ğŸ¤– **Assistant Personnel de {CREATOR}**
âš¡ **OptimisÃ© pour la vitesse et la performance**

ğŸ“¸ **Galerie Exclusive** - {len(IMAGE_GALLERY)} photos personnelles
ğŸ§  **IA AvancÃ©e** - RÃ©ponses intelligentes et rapides
ğŸ’» **GÃ©nÃ©ration de Code** - Code parfait et copiable

ğŸ¯ **Commandes Disponibles :**
/start - Menu principal avec photo
/menu - Interface complÃ¨te  
/gallery - Voir toutes mes photos
/code - GÃ©nÃ©rer du code professionnel
/models - GÃ©rer les modÃ¨les IA
/quick - Mode rÃ©ponse rapide
/photo - Photo alÃ©atoire

ğŸš€ **Pour commencer :** Envoie un message ou utilise /quick pour des rÃ©ponses ultra-rapides

ğŸ‘‘ **DÃ©veloppÃ© avec passion par {CREATOR}**
"""

def send_photo_with_retry(chat_id, photo_url, caption, max_retries=3):
    """Envoi de photo avec systÃ¨me de retry"""
    for attempt in range(max_retries):
        try:
            bot.send_photo(chat_id, photo=photo_url, caption=caption, parse_mode='Markdown')
            return True
        except Exception as e:
            if attempt == max_retries - 1:
                bot.send_message(chat_id, f"ğŸ“¸ **Photo non disponible**\n\nLien direct : {photo_url}", parse_mode='Markdown')
                return False
            time.sleep(1)
    return False

# ==================== COMMANDES OPTIMISÃ‰ES ====================
@bot.message_handler(commands=['start', 'menu'])
def start_handler(message):
    """Menu principal avec tes photos"""
    bot.send_chat_action(message.chat.id, 'upload_photo')
    
    # Envoi d'une de tes photos
    if IMAGE_GALLERY:
        your_photo = random.choice(IMAGE_GALLERY)
        photo_caption = f"ğŸ¨ **Photo Exclusive**\n\nğŸ‘‘ PropriÃ©taire : {CREATOR}\nğŸ¤– Assistant : {BOT_NAME}\nğŸ’« Collection personnelle"
        
        send_photo_with_retry(message.chat.id, your_photo, photo_caption)
    
    # Menu stylisÃ©
    menu_text = create_stylish_menu()
    bot.send_message(message.chat.id, menu_text, parse_mode='Markdown')

@bot.message_handler(commands=['gallery', 'photos', 'mesphotos'])
def gallery_handler(message):
    """Affiche toutes tes photos"""
    bot.send_chat_action(message.chat.id, 'upload_photo')
    
    if not IMAGE_GALLERY:
        bot.send_message(message.chat.id, "ğŸ“¸ **Aucune photo configurÃ©e**\n\nAjoute tes URLs dans IMAGE_GALLERY", parse_mode='Markdown')
        return
    
    gallery_info = f"""
ğŸ“¸ **MA GALERIE PERSONNELLE**

ğŸ‘‘ **PropriÃ©taire :** {CREATOR}
ğŸ–¼ï¸ **Total de photos :** {len(IMAGE_GALLERY)}
ğŸ¨ **Collection exclusive**

**Navigation :**
/photo - Photo alÃ©atoire
/start - Retour au menu
"""
    bot.send_message(message.chat.id, gallery_info, parse_mode='Markdown')
    
    # Envoi de 2 photos en preview
    preview_photos = random.sample(IMAGE_GALLERY, min(2, len(IMAGE_GALLERY)))
    for photo in preview_photos:
        send_photo_with_retry(message.chat.id, photo, f"ğŸ“¸ Photo de {CREATOR}", parse_mode='Markdown')

@bot.message_handler(commands=['photo', 'random'])
def photo_handler(message):
    """Envoie une photo alÃ©atoire"""
    bot.send_chat_action(message.chat.id, 'upload_photo')
    
    if IMAGE_GALLERY:
        random_photo = random.choice(IMAGE_GALLERY)
        caption = f"ğŸ“¸ **Photo AlÃ©atoire**\n\nğŸ‘‘ PropriÃ©taire : {CREATOR}\nğŸ¤– PartagÃ© par {BOT_NAME}\nğŸ’« Collection personnelle"
        send_photo_with_retry(message.chat.id, random_photo, caption)
    else:
        bot.send_message(message.chat.id, "âŒ **Aucune photo disponible**\n\nConfigure tes URLs dans le code.", parse_mode='Markdown')

@bot.message_handler(commands=['quick', 'rapide'])
def quick_handler(message):
    """Mode rÃ©ponse rapide avec modÃ¨le optimisÃ©"""
    bot.send_chat_action(message.chat.id, 'typing')
    
    quick_info = """
ğŸš€ **MODE RAPIDE ACTIVÃ‰**

âš¡ **Configuration optimisÃ©e :**
â€¢ ModÃ¨le : Llama-8B (le plus rapide)
â€¢ Temps rÃ©ponse : < 2 secondes
â€¢ Tokens : LimitÃ©s pour la vitesse

ğŸ’¡ **Utilisation :**
Envoie ton message et obtiens une rÃ©ponse ultra-rapide !

ğŸ”„ **Retour au mode normal :** Envoie un message normal
"""
    bot.send_message(message.chat.id, quick_info, parse_mode='Markdown')

@bot.message_handler(commands=['models'])
def models_handler(message):
    """Gestion des modÃ¨les IA"""
    bot.send_chat_action(message.chat.id, 'typing')
    
    models_text = """
ğŸ§  **MODÃˆLES IA DISPONIBLES**

"""
    
    for name, model in MODEL_CONFIG.items():
        status = "âœ… ACTUEL" if model == current_model else "ğŸŸ¢ DISPONIBLE"
        speed = "âš¡ RAPIDE" if "8b" in model else "ğŸ¯ PUISSANT"
        models_text += f"â€¢ {name} - {speed} - {status}\n"
    
    models_text += f"""
ğŸ’¡ **Recommandation :**
â€¢ Llama-8B : RÃ©ponses rapides
â€¢ Llama-70B : RÃ©ponses dÃ©taillÃ©es

ğŸ”§ **Changer :** `/model Llama-8B`
"""
    bot.send_message(message.chat.id, models_text, parse_mode='Markdown')

@bot.message_handler(commands=['model'])
def change_model_handler(message):
    """Changer de modÃ¨le IA"""
    bot.send_chat_action(message.chat.id, 'typing')
    
    try:
        args = message.text.split()
        if len(args) > 1:
            requested_model = ' '.join(args[1:])
            
            for name, model in MODEL_CONFIG.items():
                if requested_model.lower() in name.lower():
                    global current_model
                    current_model = model
                    response = f"""
ğŸ”„ **MODÃˆLE MIS Ã€ JOUR**

âœ… **Nouveau modÃ¨le :** {name}
âš¡ **Vitesse :** OptimisÃ©e
ğŸ¯ **Performance :** AmÃ©liorÃ©e

ğŸ’¡ PrÃªt Ã  recevoir vos demandes !
"""
                    break
            else:
                response = f"""
âŒ **MODÃˆLE NON TROUVÃ‰**

ğŸ“‹ **ModÃ¨les disponibles :**
{', '.join(MODEL_CONFIG.keys())}

ğŸ’¡ **Exemple :** `/model Llama-8B`
"""
        else:
            response = """
ğŸ¯ **CHANGER DE MODÃˆLE**

ğŸ’¡ **Usage :** `/model [nom]`

**Exemples :**
â€¢ `/model Llama-8B` - Pour la vitesse
â€¢ `/model Llama-70B` - Pour la prÃ©cision
"""
    except Exception as e:
        response = f"""
âŒ **ERREUR**

DÃ©tails : {str(e)}

ğŸ‘‘ **Support :** {CREATOR}
"""
    
    bot.send_message(message.chat.id, response, parse_mode='Markdown')

@bot.message_handler(commands=['code'])
def code_handler(message):
    """GÃ©nÃ©ration de code"""
    bot.send_chat_action(message.chat.id, 'typing')
    
    code_guide = """
ğŸ’» **GÃ‰NÃ‰RATEUR DE CODE**

ğŸš€ **Langages supportÃ©s :**
â€¢ Python, JavaScript, HTML/CSS
â€¢ Java, PHP, SQL
â€¢ Et bien d'autres...

ğŸ’¡ **Comment utiliser :**
"CrÃ©e un [langage] pour [description]"

**Exemples :**
â€¢ "CrÃ©e un script Python pour analyser un fichier CSV"
â€¢ "GÃ©nÃ¨re une page HTML moderne pour un portfolio"
â€¢ "Code une fonction JavaScript pour valider un formulaire"

ğŸ¯ **FonctionnalitÃ©s :**
â€¢ Code bien formatÃ© et commentÃ©
â€¢ Facile Ã  copier
â€¢ OptimisÃ© pour la performance

ğŸ‘‘ **Expert en code :** {CREATOR}
"""
    bot.send_message(message.chat.id, code_guide, parse_mode='Markdown')

# ==================== MOTEUR IA OPTIMISÃ‰ ====================
@bot.message_handler(func=lambda message: True)
def message_handler(message):
    """Gestionnaire principal optimisÃ©"""
    # Test de connexion avant de traiter
    if not test_groq_connection():
        bot.send_message(message.chat.id, 
            "ğŸ”Œ **PROBLÃˆME DE CONNEXION**\n\n"
            "L'API Groq est temporairement indisponible.\n\n"
            "ğŸ’¡ **Solutions :**\n"
            "â€¢ VÃ©rifie ta connexion Internet\n"
            "â€¢ RÃ©essaie dans 1 minute\n"
            "â€¢ Utilise un modÃ¨le diffÃ©rent avec /models\n\n"
            "ğŸ‘‘ **Support :** {CREATOR}",
            parse_mode='Markdown'
        )
        return

    bot.send_chat_action(message.chat.id, 'typing')
    
    try:
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }

        # Prompt optimisÃ© pour la vitesse
        system_prompt = f"""Tu es {BOT_NAME}, assistant IA personnel de {CREATOR}.

Tu es rapide, prÃ©cis et utile. RÃ©ponds de maniÃ¨re concise et efficace.

Si on te demande de gÃ©nÃ©rer du code, formate-le proprement avec des commentaires.

RÃ©ponds en franÃ§ais sauf demande contraire."""

        payload = {
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": message.text}
            ],
            "model": current_model,
            "max_tokens": 1024,
            "temperature": 0.7,
            "top_p": 0.9
        }

        # Timeout rÃ©duit pour Ã©viter les longs dÃ©lais
        response = requests.post(GROQ_API_URL, json=payload, headers=headers, timeout=15)
        
        if response.status_code == 200:
            data = response.json()
            answer = data["choices"][0]["message"]["content"]
            
            # DÃ©tection de code
            code_blocks = re.findall(r'```(?:[\w]*)\n?(.*?)```', answer, re.DOTALL)
            
            if code_blocks:
                formatted_response = "ğŸ’» **CODE GÃ‰NÃ‰RÃ‰** ğŸ’»\n\n"
                for i, code in enumerate(code_blocks, 1):
                    lang = "python"  # DÃ©tection automatique basique
                    if "html" in message.text.lower():
                        lang = "html"
                    elif "css" in message.text.lower():
                        lang = "css"
                    elif "javascript" in message.text.lower() or "js" in message.text.lower():
                        lang = "javascript"
                    
                    formatted_response += f"ğŸ“¦ **Bloc {i}**\n```{lang}\n{code.strip()}\n```\n\n"
                
                formatted_response += "ğŸ“‹ **Copie facile** - SÃ©lectionne et copie\nğŸ‘‘ **Expert :** {CREATOR}"
                bot.reply_to(message, formatted_response, parse_mode='Markdown')
            else:
                # RÃ©ponse normale
                final_response = f"âœ¨ **RÃ‰PONSE** âœ¨\n\n{answer}\n\n---\nğŸ¤– {BOT_NAME} par {CREATOR}"
                bot.reply_to(message, final_response, parse_mode='Markdown')
                
        else:
            error_msg = f"""
âŒ **ERREUR API**

DÃ©tails : Code {response.status_code}

ğŸ’¡ **Solutions rapides :**
â€¢ RÃ©essaye maintenant
â€¢ Utilise `/model Llama-8B` pour plus de vitesse
â€¢ VÃ©rifie ta connexion

ğŸ‘‘ **Technical Support :** {CREATOR}
"""
            bot.reply_to(message, error_msg, parse_mode='Markdown')
            
    except requests.exceptions.Timeout:
        bot.reply_to(message,
            "â° **DÃ‰LAI DÃ‰PASSÃ‰**\n\n"
            "La requÃªte prend trop de temps.\n\n"
            "ğŸš€ **Actions rapides :**\n"
            "â€¢ Utilise `/quick` pour le mode rapide\n"
            "â€¢ Change de modÃ¨le avec `/models`\n"
            "â€¢ RÃ©duis la complexitÃ© de ta question\n\n"
            "ğŸ‘‘ **OptimisÃ© par :** {CREATOR}",
            parse_mode='Markdown'
        )
        
    except Exception as e:
        bot.reply_to(message,
            "ğŸ”´ **ERREUR INATTENDUE**\n\n"
            f"DÃ©tails : {str(e)}\n\n"
            "ğŸ‘‘ **Support immÃ©diat :** {CREATOR}",
            parse_mode='Markdown'
        )

# ==================== DÃ‰MARRAGE ====================
if __name__ == "__main__":
    print(f"""
ğŸ¯ {BOT_NAME} - {VERSION}
ğŸ‘‘ CrÃ©ateur : {CREATOR}
âš¡ ModÃ¨le : {current_model}
ğŸ“¸ Photos : {len(IMAGE_GALLERY)}
ğŸš€ Statut : OpÃ©rationnel

ğŸ’¡ Pour configurer tes photos :
Remplace les URLs dans IMAGE_GALLERY par tes propres images
    """)
    
    try:
        bot.infinity_polling()
    except Exception as e:
        print(f"âŒ Erreur : {e}")
        print(f"ğŸ‘‘ Contact : {CREATOR}")
